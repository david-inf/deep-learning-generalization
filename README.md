# Deep-learning-generalization

A work on generalization in deep learning

### Details

Supervised learning on CIFAR10

- Models:
    - MLP
    - (Simple-Net)
    - AlexNet
    - Inception-V3
- Optimization
    - Optimizer: SGD

## Experiments

Experiments for figure 1
- Loss per training step varying randomization test
- Time to overfit (reach zero-loss) againts label corruption for each network
- Test error against label corruption for each network

| Experiment | Results |
| ---------- | ------- |
| Learning curves. Fixed net with varying randomization in data. | plot |
| Convergence slowdown. Time to overfit at different label corruption levels. | plot |
| Generalization error growth. Same as the previous but we look for the test error. | plot |

Experiments for figure 2
- 

## References
